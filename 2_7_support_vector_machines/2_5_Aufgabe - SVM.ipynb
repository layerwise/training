{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.5) SVM und das XOR-Problem <span style=\"color:green; font-size:1em\">(o)</span> <span style=\"font-size:1em\">&#x1F4D7;</span>\n",
    "\n",
    "In dieser Aufgabe generieren Sie schrittweise das kanonische XOR-Problem (das Entweder-Oder-Problem), dass durch eine einfache logistische Regression nicht lösbar ist. Das XOR-Problem lässt sich auch verstehen als ein sogenanntes *Gaussian Mixture Model*, in dem die Daten einer Summe verschiedener Normalverteilungen mit verschiedenen Positionen entstammen. Die Generierung der Daten wird von der Funktion `get_xor_data` in der begleitenden Python-File `utils_svm.py` für Sie übernommen.\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\"> (a) </span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Erstellen Sie einen Trainingsdatensatz mit $200$ Datenpunkten mit der Funktion `get_xor_data` und plotten Sie die Datenpunkte, indem Sie sie entsprechend ihrer Klasse (hier: $y_T^{(i)} \\in \\{-1, +1\\}$) einfärben. Warum kann das Problem nicht durch eine logistische Regression gelöst werden?\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\"> (b) </span>** <span style=\"font-size:2em\">&#x1F4D9;</span> Benutzen Sie die in Scikit-Learn verfügbare SVM-Implementation und trainieren Sie ein Modell mit den Default-Parametern und dem *Radial Basis Function*-Kernel (`kernel='rbf'`). Plotten Sie die Entscheidungsgrenze des Modells (etwa mit `plt.contour` oder durch eine in vorherigen Tutorials bereitgestellte Funktion).\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\"> (c) </span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Erzeugen Sie einen Testdatensatz mit weiteren $200$ Datenpunkten und berechnen Sie die Korrekt-Klassifikationsrate (auch *accuracy* genannt) auf den Testdaten.\n",
    "\n",
    "**<span style=\"color:orange; font-size:2em\"> (d) </span>** <span style=\"font-size:2em\">&#x1F4D9;</span> Teilen Sie nun ihren Trainingsdatensatz in zwei Datensätze mit einmal $160$ und einmal $40$ Datenpunkten. Den kleineren Datensatz nennen wir den Validierungsdatensatz. Variieren Sie nun die Werte für die Parameter $C$ und $\\gamma$ der SVM auf einer logarithmischen Skala:\n",
    "\n",
    "$$\n",
    "C \\in \\{ 2^{-6}, 2^{-4}, ..., 2^{10}\\}\n",
    "$$\n",
    "$$\n",
    "\\gamma \\in \\{ 2^{-5}, 2^{-3}, ..., 2^9\\}\n",
    "$$\n",
    "\n",
    "und trainieren Sie für jede Kombination eine SVM auf den verbliebenen $160$ Trainingsdatenpunkten. Evaluieren Sie jedes Modell auf dem Validierungsdatensatz. Plotten Sie eine *heatmap* des Ergebnisses. Finden Sie so die beste Kombination der Werte für $C$ und $\\gamma$.\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\"> (e) </span>** <span style=\"font-size:2em\">&#x1F4D9;</span> Trainieren Sie nun eine SVM mit den besten Werten der Hyperparameter aus der vorherigen Aufgabe auf dem kompletten ursprünglichen Trainingsdatensatz mit $200$ Datenpunkten. Validieren Sie das Modell auf dem Testdatensatz und vergleichen Sie mit dem Ergebnis aus **a)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# um die begleitende Datei utils_svm.py auf diese Weise zu importieren,\n",
    "# laden Sie sie zunächst aus dem Datenaustausch herunter und platzieren\n",
    "# Sie sie am besten genau in dem Ordner, in dem Sie dieses Notebook gespeichert haben\n",
    "import utils_svm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.svm import SVC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
