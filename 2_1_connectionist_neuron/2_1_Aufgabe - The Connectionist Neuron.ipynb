{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.1.1) Mit Matrizen und Vektoren arbeiten <span style=\"color:green; font-size:1em\">(o)</span>  <span style=\"font-size:1em\">&#x1F4D7;</span>\n",
    "\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\">(a)</span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Laden Sie den Datensatz `ZonkoAndTydum.csv` aus dem Datenaustausch herunter. Laden Sie den Datensatz ein, sodass die Beobachtungen/Features in einer Matrix $\\mathbf{X} \\in \\mathbb{R}^{200 * 2}$, also mit 200 Zeilen und 2 Spalten, und die Kennzeichnungen/Labels $\\mathbf{y}$ in einem Vektor mit 200 Elementen gespeichert sind.\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\">(b)</span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Erzeugen Sie einen Vektor mit 200 Elementen und setzen Sie alle Elemente auf den Wert $1$.\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\">(c)</span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Verbinden Sie den Vektor mit den Einsen aus der vorherigen Aufgabe mit der Matrix $\\mathbf{X}$, sodass diese nun eine zusätzliche Spalte hat. Der Vektor mit Einsen soll die erste Spalte der Matrix sein.\n",
    "\n",
    "**<span style=\"color:orange; font-size:2em\">(d)</span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Multiplizieren Sie jeden Datenpunkt in $\\mathbf{X}$ (d.h. jede Zeile) mit dem Vektor $\\mathbf{w} := (-1.05, 2.183, 2.171)$. Mit Multiplikation ist das Skalarprodukt gemeint, d.h. für einen gegebenen Zeilenvektor $\\mathbf{x}^{(i)}$ ist die Ausgabe, hier $h^{(i)}$ genannt, auf folgende Weise zu berechnen:\n",
    "\n",
    "$$\n",
    "h^{(i)} = \\mathbf{w} \\cdot \\mathbf{x}^{(i)} = w_1 \\cdot x_1^{(i)} + w_2 \\cdot x_2^{(i)} + w_3 \\cdot x_3^{(i)}\n",
    "$$\n",
    "\n",
    "\n",
    "Speichern Sie das Ergebnis dieser \"Projektion\" in einem Vektor $\\mathbf{h} = (h^{(1)}, h^{(2)}, ..., h^{(200)})$.\n",
    "\n",
    "(*Hinweis: die Berechnung von $\\mathbf{h}$ kann auf unterschiedliche Weise erfolgen: entweder durch ein oder mehrere for-Schleifen, oder durch eine geeignete Matrixmultiplikation mit* `np.dot` *oder* `np.matmul`.)\n",
    "\n",
    "**<span style=\"color:orange; font-size:2em\">(e)</span>** <span style=\"font-size:2em\">&#x1F4D9;</span> Führen Sie nun eine alternative Berechnung von $\\mathbf{h}$ durch: Ignorieren Sie die erste Spalte der Matrix $\\mathbf{X}$, die Sie zuvor in Aufgabe (b) und (c) erzeugt haben. Definieren Sie einen *bias* $\\theta=-1.05$ und führen Sie nun eine ähnliche Berechnung wie in Aufgabe (d) auf den verbliebenen zwei Spalten der Matrix $\\mathbf{X}$ und mit dem Vektor $\\mathbf{w}' := (2.183, 2.171)$ aus:\n",
    "\n",
    "$$\n",
    "h^{(i)} = \\mathbf{w}' \\cdot \\mathbf{x}^{(i)} + \\theta = w_1 \\cdot x_1^{(i)} + w_2 \\cdot x_2^{(i)} + \\theta\n",
    "$$\n",
    "\n",
    "Vergewissern Sie sich, dass das Ergebnis mit dem aus Aufgabe (d) identisch ist.\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\">(f)</span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Visualisieren Sie das Ergebnis aus den vorherigen Aufgaben: Erzeugen Sie einen *Scatterplot* der Variablen `x1 [Durchmesser]` und `x2 [Gewicht]` und verwenden Sie die Kennzeichnungen $\\mathbf{y}$ um die Beobachtungen mit zwei verschiedenen Farben einzufärben. Wiederholen Sie das Ganze mit den vorhergesagten Kennzeichnungen $\\mathbf{h}$ (dem Ergebnis der Projektion), wodurch die Datenpunkte entlang einer graduellen Farbskala eingefärbt werden sollten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.1.2) Klassifikation mit dem Connectionist Neuron <span style=\"color:green; font-size:1em\">(o)</span> -  <span style=\"color:orange; font-size:1em\">(oo)</span> <span style=\"font-size:1em\">&#x1F4D7;</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz `ZonkoAndTydum.csv` enthält jeweils 200 Messungen von zwei Variablen (`x1 [Durchmesser]` und `x2 [Gewicht]`) von zwei Typen von extraterristrischen Mikroorganismen. Der Typ des Organismus ist durch die Spalte `y` angezeigt.\n",
    "\n",
    "In dieser Aufgabe werden sie ein *Connectionst Neuron* mit einer binären Ausgabefunktion $f(h)$ verwenden, um die Datenpunkte zu klassifizieren. Das heißt für einen Datenpunkt $\\textbf{x}^{(i)}$ wird die vorhergesagte Klasse folgendermaßen berechnet: \n",
    "\n",
    "$$\n",
    "\\hat{y}(\\mathbf{x}^{(i)}) = f(h) = f(\\mathbf{w}^T \\mathbf{x}^{(i)} - \\theta)\n",
    "$$\n",
    "\n",
    "wobei\n",
    "\n",
    "$$\n",
    "f(h) \\cases{\n",
    "1 \\quad \\text{ falls } \\quad h \\geq 0 \\\\\n",
    "0 \\quad \\text{ sonst }\n",
    "}\n",
    "$$\n",
    "\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\">(a)</span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Setzen Sie den *bias* $\\theta$ zunächst auf $0$. Generieren Sie einen Satz von 19 Parametervektoren $\\mathbf{w} = (w_1, w_2)$ folgendermaßen:\n",
    "\n",
    "$w_1 = \\cos(\\frac{\\gamma}{180} \\pi)$\n",
    "\n",
    "$w_2 = \\sin(\\frac{\\gamma}{180} \\pi)$\n",
    "\n",
    "wobei $\\gamma = 0, 10, 20, ..., 180$. Diese Parametervektoren sollten den oberen Halbkreis mit Radius $1$ des Koordinatessystems abdecken. Verwenden Sie `numpy`'s Funktionen und Variablen `np.cos`, `np.sin` und `np.pi`. Es gilt $||\\mathbf{w}||^2 = w_1^2 + w_2^2 = 1$ für alle diese Parametervektoren. Visualisieren Sie alle 19 Parametervektoren (zum Beispiel mit `plt.plot`)\n",
    "\n",
    "**<span style=\"color:orange; font-size:2em\">(b)</span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Bestimmen Sie für jeden der Parametervektoren aus der vorherigen Aufgabe die Genauigkeit der Vorhersage (Korrekte-Klassifikations-Rate / Accuracy) des entsprechenden Modells (Neurons). Gehen Sie dazu folgendermaßen vor: Benutzen Sie die oben genannte Formel, um für jeden Eintrag/jede Zeile der Matrix $\\mathbf{X}$ die Ausgabe $\\hat{y}$ zu bestimmen. Vergleichen Sie das Ergebnis mit den tatsächlichen Klassen, die durch die Spalte `y` in `ZonkoAndTydum.csv` gegeben sind.\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\">(c)</span>** <span style=\"font-size:2em\">&#x1F4D7;</span> Plotten Sie die Genauigkeit für jeden Parametervektor gegen den entsprechenden Wert $\\gamma$.\n",
    "\n",
    "**<span style=\"color:orange; font-size:2em\">(d)</span>** <span style=\"font-size:2em\">&#x1F4D9;</span> Wählen Sie den Parametervektor $\\mathbf{w}$, der die beste Performance erreicht und halten Sie diesen fest. Varieren Sie nun den *bias* $\\theta$, indem Sie Werte zwischen $-3$ und $3$ generieren und erneut für jeden dieser Werte die Genauigkeit der Vorhersage berechnen. Wählen Sie den Wert für $\\theta$, der hier die beste Performance erreicht.\n",
    "\n",
    "**<span style=\"color:orange; font-size:2em\">(e)</span>** <span style=\"font-size:2em\">&#x1F4D9;</span> Plotten Sie die (zweidimensionalen) Datenpunkte und färben Sie sie entsprechend ihrer vorhergesagten Klasse (benutzen Sie dafür die besten Werte aus der vorherigen Aufgabe). Plotten Sie den Parametervektor, der dieses Ergebnis erzielt hat. Wie interpretieren Sie den Plot?\n",
    "\n",
    "**<span style=\"color:orange; font-size:2em\">(f)</span>** <span style=\"font-size:2em\">&#x1F4D9;</span> Finden Sie nun die besten Werte für $\\mathbf{w}$ und $\\theta$ gleichzeitig, indem Sie über alle Kombinationen von $\\gamma$ und $\\theta$ hinweg suchen (passen Sie den Suchraum eventuell an, wenn die Berechnung zu lange dauert). Plotten Sie eine *heatmap* der *classification performance* von allen Kombinationen.\n",
    "\n",
    "**<span style=\"color:green; font-size:2em\">(g)</span>** <span style=\"font-size:2em\">&#x1F4D9;</span> Kann das Vorgehen aus den vorherigen Aufgaben auf ein beliebiges Klassifikationsproblem angewendet werden? Warum oder warum nicht? Falls nicht, machen Sie einen Vorschlag, wie das Verfahren verbessert werden könnte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2.1.3) Objekt-orientierte Programmierung des Connectionist Neuron <span style=\"color:red; font-size:1em\">(ooo)</span> <span style=\"font-size:1em\">&#x1F4D8;</span>\n",
    "\n",
    "Implementieren Sie die Funktion `predict` der im Unterricht benutzten Klasse `InteractiveLogisticRegression`, unten noch einmal dargestellt. Denken Sie daran, dass die Klasse nur Daten mit 2 Features behandeln kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "\n",
    "class InteractiveLogisticRegression:\n",
    "    def __init__(self, w1_range=(-5.0, 5.0, 0.05), w2_range=(-5.0, 5.0, 0.05), bias_range=(-3.0, 3.0, 0.01)):\n",
    "        self.w1 = None\n",
    "        self.w2 = None\n",
    "        self.bias = None\n",
    "        self.w1_range = w1_range\n",
    "        self.w2_range = w2_range\n",
    "        self.bias_range = bias_range\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if not X.ndim == 2:\n",
    "            raise ValueError\n",
    "        if not X.shape[1] == 2:\n",
    "            raise ValueError(\"Matrix X should have only two features.\")\n",
    "            \n",
    "        xx = np.linspace(0, 2 * np.pi)\n",
    "        fig = plt.figure(figsize=(6,6))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.set_ylim(-0.2, 1.2)\n",
    "        ax.set_xlim(-0.2, 1.2)\n",
    "        ax.set_aspect(\"equal\")\n",
    "\n",
    "        scatter_handle = plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "\n",
    "        w1 = 0.1\n",
    "        w2 = 1.0\n",
    "        final_w1 = w1\n",
    "        final_w2 = w2\n",
    "\n",
    "        projection_vector, = ax.plot([0, w1], [0, w2], color=\"blue\")\n",
    "        projection_vector2, = ax.plot([-w1, w1], [-w2, w2], linestyle=\"--\", color=\"blue\")\n",
    "        decision_boundary, = ax.plot([0, -w2], [0, w1], color=\"orange\")\n",
    "        vector_tip, = ax.plot(w1, w2, marker=\"x\", markersize=15, color=\"blue\")\n",
    "        ax.plot(0, 0, markersize=10, color=\"red\", marker=\"o\")\n",
    "\n",
    "        xx = np.linspace(-2, 2, num=100)\n",
    "        yy = - (w1 / w2) * xx\n",
    "        top_filler = ax.fill_between(xx, y1=-10, y2=yy, color=\"purple\", alpha=0.1)\n",
    "        bottom_filler = ax.fill_between(xx, y1=yy, y2=10, color=\"yellow\", alpha=0.1)\n",
    "\n",
    "        def update(w1=0.1, w2=1.0, bias=0.0):\n",
    "            vector_tip.set_data(w1, w2)\n",
    "            \n",
    "            self.w1 = w1\n",
    "            self.w2 = w2\n",
    "            self.bias = bias\n",
    "\n",
    "            if not w1:\n",
    "                w1 = 0.0001\n",
    "            if not w2:\n",
    "                w2 = 0.0001\n",
    "\n",
    "            w = np.array([w1, w2])\n",
    "\n",
    "            projection_vector.set_data([0, w1], [0, w2])\n",
    "            decision_boundary.set_data([-2, 2], [- w1/w2 * (-2) + bias/w2, - w1/w2 * 2 + bias/w2])\n",
    "\n",
    "            if not w2 == 0:\n",
    "                yy = - (w1 / w2) * xx + bias / w2\n",
    "                ax.collections = ax.collections[:1]\n",
    "                if w2 > 0:\n",
    "                    top_filler = ax.fill_between(xx, y1=-10, y2=yy, color=\"purple\", alpha=0.1)\n",
    "                    bottom_filler = ax.fill_between(xx, y1=yy, y2=10, color=\"yellow\", alpha=0.1)\n",
    "                else:\n",
    "                    top_filler = ax.fill_between(xx, y1=-10, y2=yy, color=\"yellow\", alpha=0.1)\n",
    "                    bottom_filler = ax.fill_between(xx, y1=yy, y2=10, color=\"purple\", alpha=0.1)\n",
    "\n",
    "            w /= np.linalg.norm(w)\n",
    "            w *= 5\n",
    "            w1, w2 = w\n",
    "            projection_vector2.set_data([-w1, w1], [-w2, w2])         \n",
    "\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        interactive_plot = interactive(update, w1=(-6.0, 6.0, 0.05), w2=(-5.0, 5.0, 0.05), bias=(-3.0, 3.0, 0.01))\n",
    "        return interactive_plot\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # TODO\n",
    "        \n",
    "        # (Für noch nicht vollständige Funktionen einer Klasse sollte\n",
    "        # immer ein `NotImplementedError` ge-raise-t werden, um einer BenutzerIn\n",
    "        # zu signalisieren, dass die Funktion noch nicht benutzbar ist.)\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
