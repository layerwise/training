{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEhKDHcsak2j"
   },
   "source": [
    "## 1. Hyperparametersuche\n",
    "\n",
    "Fast alle Machine Learning Modelle verfügen über sogenannte Hyperparamter. Dies sind veränderliche Bestandteile des Modells bzw. des Trainings im weiteren Sinne (also auch Vorverarbeitungen der Daten), die nicht durch die Daten bestimmt werden können. Dies ist im Kontrast zu Parametern wie zum Beispiel den Gewichten in einem Neuronenmodell, die eben genau durch die Daten bestimmt werden.\n",
    "\n",
    "Hyperparameter müssen abgestimmt werden ohne dabei auf die Testdaten zurückzugreifen. Werden Testdaten zur Abstimmung verwendet, nennt man diesen methodischen Fehler *data leakage* - also das Einsickern der Testdaten in den Lernprozess. Damit einher geht eine möglicherweise falsch geschätzte Generalisierungsfähigkeit des Modells - die Testdaten sind keine Testdaten mehr.\n",
    "\n",
    "Der korrekte Ansatz zur Abstimmung der Hyperparameter ist die Benutzung eines Validierungsdatensatzes. Ein Teil der Trainingsdaten wird zur Validierung von Modellen mit verschiedenen Hyperparametern genutzt - die Testdaten bleiben unangetastet.\n",
    "\n",
    "Folgende Hyperparameter haben wir kennengelernt:\n",
    "\n",
    "- Lineare Regression\n",
    "    - `Ridge` versus `Lasso` versus `ElasticNet` - Art der Regularisierung\n",
    "    - `alpha` - Stärke der Regularisierung\n",
    "    - `degree` - Grad einer möglichen polynomischen Expansion\n",
    "- Logistische Regression\n",
    "    - `C` - inverse Stärke der Regularisierung\n",
    "    - `penalty= \"l2\" / \"l1\" / \"elasticnet\"`- Art der Regularisierung\n",
    "- Decision Trees\n",
    "    - `max_depth`\n",
    "- Random Forest\n",
    "    - `max_depth`\n",
    "    - `n_estimators`\n",
    "- Gradient Boosting\n",
    "    - `max_depth`\n",
    "    - `n_estimators`\n",
    "    - `learning_rate`\n",
    "- Support Vector Machines\n",
    "    - `C` - inverse Stärke der Regularisierung\n",
    "    - `kernel = \"rbf\" / \"linear\"`\n",
    "    - `gamma`\n",
    "- K-Nearest Neighbors\n",
    "    - `n_neighbors`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL4ivOTwb6Ym"
   },
   "source": [
    "### 1.1 Daten und Vorbereitung\n",
    "\n",
    "Wir untersuchen ein künstlich erstelltes Regressionsproblem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "wEKfAUrFa-t-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TODO: Scikit-Learn Importe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E-zXQgOncF6Q"
   },
   "outputs": [],
   "source": [
    "# TODO: Hilfsfunktion zum Erstellen einer polynomischen Regression\n",
    "def get_regression(alpha=1.0, degree=2):\n",
    "    model = None\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bq6spA1Sak24"
   },
   "outputs": [],
   "source": [
    "# Hilfsfunktion zu Generierung eines Toy-Datensatzes\n",
    "# für ein Regressionsproblem\n",
    "def make_data(N=30, err=0.8, rseed=1):\n",
    "    # randomly sample the data\n",
    "    rng = np.random.RandomState(rseed)\n",
    "    X = rng.rand(N, 1) ** 2\n",
    "    y = 10 - 1. / (X.ravel() + 0.1)\n",
    "    if err > 0:\n",
    "        y += err * rng.randn(N)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "XDnGfpUebMVX",
    "outputId": "2b54758c-16a9-45e4-fbf2-f7543b69bdac"
   },
   "outputs": [],
   "source": [
    "# TODO: Visualisierung der Daten\n",
    "# shape [N, 1] für X und [N, ] für y\n",
    "X, y = make_data(N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mfCO2kc4bxgv"
   },
   "outputs": [],
   "source": [
    "# TODO: Trainings- und Testdaten aufspalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YyXSEJKFc1tg",
    "outputId": "1f05f78a-28c2-4687-a79f-c75e83b4bfc1"
   },
   "outputs": [],
   "source": [
    "# TODO: Fitten des Modells ohne Hyperparametersuche\n",
    "# TODO: Evaluieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M0XMVBRebZ-"
   },
   "source": [
    "### 1.2. Hyperparametersuche per Scikit-Learn API\n",
    "\n",
    "Scikit-Learn stellt zur Abstimmung der Hyperparameter verschiedene Klassen zur Verfügung. Diese Klassen führen die nötigen for-Schleifen intern aus. \n",
    "\n",
    "![gridsearch_cv](https://raw.githubusercontent.com/layerwise/training/main/assets/gridsearch_cv.png)\n",
    "\n",
    "Die obenstehende Graphik ist durch `GridSearchCV` von Scikit-Learn umgesetzt.\n",
    "\n",
    "```python\n",
    ">>> from sklearn.model_selection import GridSearchCV\n",
    ">>> GridSearchCV?\n",
    "```\n",
    "\n",
    "Wir müssen von außen nur folgendes festlegen: \n",
    "\n",
    "- `param_grid` - den Suchraum der Hyperparameter\n",
    "- `model` - das zu Grunde liegende Modell\n",
    "- `cv` - die Anzahl der Kreuzvalidierungs-Faltungen, typischerweise 3, 5 oder 10\n",
    "- `scoring` - die zu optimierende Metrik\n",
    "\n",
    "Um alle möglichen Evaluationsmetriken anzuzeigen ist folgender Code hilfreich\n",
    "\n",
    "```python\n",
    ">>> from sklearn.metrics import SCORERS\n",
    ">>> sorted(SCORERS.keys())\n",
    "```\n",
    "\n",
    "Die Klasse `GridSearchCV` verhält sich ganz im Sinne von Scikit-Learn ganz genau so wie jedes andere Basis-Modell auch. Das heißt es gibt dort eine `fit` und `predict` Funktion, in denen alle Arbeitsschritte schon integriert sind.\n",
    "\n",
    "Nach einem erfolgreichen Fit, das heißt einer Abstimmung der Hyperparameter durch `GridSearchCV` sind unter anderem folgende Attribute relevant:\n",
    "\n",
    "- `best_estimator_`\n",
    "- `best_params_`\n",
    "- `best_score_`\n",
    "- `cv_results_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import GridSearchCV\n",
    "# TODO: Fitten des GridSearchCV Modells\n",
    "# TODO: Evaluieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tgq5EoOowUu0"
   },
   "source": [
    "### 1.3 Hyperparametersuche durch vorgefertigte Modelle\n",
    "\n",
    "Die Klasse `GridSearchCV` ist für beliebige Modelle (und besonders für Pipelines) nutzbar. Für viele Modelle allerdings ist die Abstimmung von Hyperparametern so alltäglich, dass es spezialisierte Klassen gibt.\n",
    "Diese sind:\n",
    "- `RidgeCV`\n",
    "- `LassoCV`\n",
    "- `ElasticNetCV`\n",
    "- `LogisticRegressionCV`\n",
    "\n",
    "Diese setzen exakt das um, was `GridSearchCV` auch könnte, also sind folgende Codes identisch\n",
    "\n",
    "```python\n",
    ">>> model = GridSearchCV(\n",
    "...     Ridge(),\n",
    "...     param_grid={\"alpha\": [0.01, 0.1, 1.0]})\n",
    ">>> model.fit(X, y)\n",
    "```\n",
    "\n",
    "und\n",
    "\n",
    "```python\n",
    ">>> model = RidgeCV(alphas=[0.01, 0.1, 1.0])\n",
    ">>> model.fit(X, y)\n",
    "```\n",
    "\n",
    "![gridsearch_cv](https://raw.githubusercontent.com/layerwise/training/main/assets/gridsearch_cv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import RidgeCV\n",
    "# TODO: Fit\n",
    "# TODO: Evaluieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFyIWHIjyCQS"
   },
   "source": [
    "### 1.4. Hyperparametersuche durch Zufallssuche\n",
    "\n",
    "Im Allgemeinen ist die sogenannte erschöpfende Gittersuche nicht nötig und auch nicht empfehlenswert, wie anhand folgender Graphik erkennbar. Dann kann statt `GridSearchCV` besser `RandomizedSearchCV` verwendet werden.\n",
    "\n",
    "![gridsearch_vs_randomsearch](https://raw.githubusercontent.com/layerwise/training/main/assets/gridsearch_vs_randomsearch.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_Fhm_P1yNCX",
    "outputId": "ac07b829-604f-4bc5-9f47-b6286ed2caae"
   },
   "outputs": [],
   "source": [
    "# TODO: Import RandomizedSearchCV\n",
    "# TODO: Fit\n",
    "# TODO: Evaluieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgCkLCQAak26"
   },
   "source": [
    "## 2. Kreuzvalidierung\n",
    "\n",
    "Die Kreuzvalidierung kann nicht nur zur Abstimmung von Hyperparametern verwendet werden. Tatsächlich ist ihre vornehmliche Funktion, die Generalisierungsfähigkeit des Modells besser zu schätzen. Statt eines einzigen Testdatensatzes, der immer zufälligen Schwankungen ausgesetzt ist und damit zu einer zufälligen Schätzung der Generalisierungsfähigkeit führt, benutzt die Kreuzvalidierung 3, 5 oder 10 solche Testdatensätze. Am Ende wird aus den einzelnen Schätzungen ein Mittelwert gebildet, von dem man zeigen kann, dass er die tatsächliche Generalisierung genauer schätzt. Wir sind also vor über-optimistischen und unter-pessimistischen Schätzungen gefeit. Wann immer genug Rechenleistung vorhanden ist, ist die Kreuzvalidierung der Testdaten-Methode vorzuziehen.\n",
    "\n",
    "In Scikit-Learn lässt sich die Kreuzvalidierung mit `cross_val_score` umsetzen. Wichtig zu beachten ist, dass ein dedizierter Trainings-Test-Split hier **nicht** erforderlich ist. Der Funktion `cross_val_score` wird der Gesamtdatensatz übergeben.\n",
    "\n",
    "![crossvalidation](https://raw.githubusercontent.com/layerwise/training/main/assets/crossvalidation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-OLgrd8ak29",
    "outputId": "a4fbfe37-82cf-4087-95c9-1aebac62f1ae"
   },
   "outputs": [],
   "source": [
    "# TODO: Import cross_val_score\n",
    "# TODO: Evaluation mit Kreuzvalidierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcPEnj4Gak2-"
   },
   "source": [
    "## 3. Verschachtelte Kreuzvalidierung\n",
    "\n",
    "Die verschachtelte Kreuzvalidierung nutzt die Methode der Kreuzvalidierung gleichzeitg sowohl für die Abstimmung von Hyperparametern und zur besseren Schätzung der Generalisierungsfähigkeit. In Scikit-Learn ist die Umsetzung denkbar einfach: wir verbinden einfach `GridSearchCV` mit `cross_val_score`.\n",
    "\n",
    "![nested_crossvalidation](https://raw.githubusercontent.com/layerwise/training/main/assets/nested_crossvalidation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aVXGeTEtak3A",
    "outputId": "472a0d2c-da0c-4d9a-dc1c-ec5a6b9a8c34"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Hyperparameter, Kreuzvalidierung.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
