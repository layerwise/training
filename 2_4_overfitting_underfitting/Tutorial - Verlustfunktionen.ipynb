{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "from ipywidgets import interactive\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib widget\n",
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten generieren\n",
    "\n",
    "Generiere Trainings- und Testdaten mit einem Merkmal und einer kontinuierlichen Zielvariablen.\n",
    "Zwischen den Variabeln herrscht ein logistischer Zusammenhang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# der wahre funktionale Zusammenhang zwischen\n",
    "def true_function(x):\n",
    "    f = 5 / (1 + np.exp(-x + 2))\n",
    "    return f\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "# Daten - Beobachtungen / Merkmale\n",
    "x_train = 10 * rng.rand(20)\n",
    "x_test = 10 * rng.rand(20)\n",
    "\n",
    "# Daten - Zielvariablen\n",
    "y_train = true_function(x_train) + 0.5 * rng.randn(20)\n",
    "y_test = true_function(x_test) + 0.5 * rng.randn(20)\n",
    "\n",
    "# Zum Plotten\n",
    "xx = np.linspace(0, 10)\n",
    "ff = true_function(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Visualisierung der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2157c3f39974d9aa0e4b24884df8ebc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2de46006d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "# plt.plot(xx, ff)\n",
    "plt.scatter(x_train, y_train, alpha=0.7)\n",
    "plt.scatter(x_test, y_test, alpha=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Visualisierung der Verlustfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions and variables zur Darstellung der Verlustfunktion\n",
    "def empirical_risk(w, b, x_sample, y_sample):\n",
    "    # makes heavy use of broadcasting\n",
    "    W = np.repeat(w[..., np.newaxis], x_sample.shape[0], axis=-1)\n",
    "    B = np.repeat(b[..., np.newaxis], x_sample.shape[0], axis=-1)\n",
    "    Y_pred = W * x_sample + B\n",
    "    loss = np.mean((Y_pred - y_sample)**2, axis=-1)\n",
    "    return loss\n",
    "\n",
    "def weight_norm(W, B):\n",
    "    return W**2 + B**2\n",
    "\n",
    "def L1_norm(W, B):\n",
    "    return np.abs(W) + np.abs(B)\n",
    "\n",
    "ws = np.linspace(-10, 10, 1000)\n",
    "bs = np.linspace(-10, 10, 1000)\n",
    "\n",
    "def get_argmin(L):\n",
    "    argmin = np.argmin(L)\n",
    "    argmin = np.unravel_index(argmin, L.shape)\n",
    "    \n",
    "    return ws[argmin[0]], bs[argmin[1]]\n",
    "\n",
    "W, B = np.meshgrid(ws, bs)\n",
    "L = empirical_risk(W, B, x_train, y_train)\n",
    "L_reg = weight_norm(W, B)\n",
    "L_reg_l1 = L1_norm(W, B)\n",
    "\n",
    "\n",
    "L_test = empirical_risk(W, B, x_test, y_test)\n",
    "\n",
    "L_min, L_max = L.min(), L.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Empirsche Verlustfunktion ohne Regularisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b304e3f6468d48bfa72a9721421dd99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.contour3D(W, B, L, 50, cmap=\"viridis\")\n",
    "ax.set_xlabel(r\"$w$\")\n",
    "ax.set_ylabel(r\"$b$\")\n",
    "ax.set_zlabel(r\"$\\mathcal{L}_{E}$\");\n",
    "ax.view_init(30, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Regularisierungsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7435e70fe10473881cc20a613e08784",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "ax.contour3D(W, B, L_reg, 50, cmap=\"Greens\")\n",
    "# ax.contour3D(W, B, lambda_*L_reg, 50, cmap=\"Greens\")\n",
    "# ax.contour3D(W, B, L_reg_l1, 50, cmap=\"Greens\")\n",
    "\n",
    "ax.set_xlabel(r\"$w$\")\n",
    "ax.set_ylabel(r\"$b$\")\n",
    "ax.set_zlabel(r\"$\\mathcal{L}_{reg}$\");\n",
    "ax.view_init(30, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Empirische Verlustfunktion + Regularisierungsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e401c999387445a78a3029f6c879e806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c41a45dc0d9456790179c938a09ed71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "alpha = 1.0\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.contour3D(W, B, L + alpha * L_reg, 50, cmap=\"rainbow\")\n",
    "ax.set_xlabel(r\"$w$\")\n",
    "ax.set_ylabel(r\"$b$\")\n",
    "ax.set_zlabel(r\"$\\mathcal{L}_E + \\mathcal{L}_{reg}$\");\n",
    "ax.view_init(30, 75)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "ax.contour3D(W, B, L, 50, cmap=\"viridis\")\n",
    "\n",
    "ax.set_xlabel(r\"$w$\")\n",
    "ax.set_ylabel(r\"$b$\")\n",
    "ax.set_zlabel(r\"$\\mathcal{L}_E$\");\n",
    "ax.view_init(30, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4 Empirische Verlustfunktion vs Test-Verlustfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e9ab7bc4f842e7b86e81f9e2c4be72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpha = 5.0\n",
    "\n",
    "plt.close(\"all\")\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.contour(W, B, L, 50, cmap=\"viridis\")\n",
    "plt.title(r\"$\\mathcal{L}_E$\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.contour(W, B, L + alpha*L_reg , 50, cmap=\"rainbow\")\n",
    "plt.title(r\"$\\mathcal{L}_E + \\alpha \\cdot \\mathcal{L}_{reg}$\")\n",
    "\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.contour(W, B, L_test, 50, cmap=\"seismic\")\n",
    "plt.title(r\"$\\mathcal{L}_T$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
