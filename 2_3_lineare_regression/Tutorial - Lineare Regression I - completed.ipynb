{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um dieses Tutorial auszuführen brauchen wir interaktives Plotting. Dieses ist in Jupyter Notebooks prinzipiell einfach möglich mit der integrierten Bibliothek `ipywidgets`. Diese Bibliothek erfordert allerdings versionsabhängig verschiedene sogenannte Backends, nämlich entweder\n",
    "\n",
    "```python\n",
    "%matplotlib widget\n",
    "# oder\n",
    "%matplotlib notebook\n",
    "```\n",
    "\n",
    "die mit der sogenannten Jupyter-Magic (das Prozentzeichen) aktiviert werden müssen. Jedes Mal, wenn wir eines dieser Backends aktivieren, kann es nicht mehr geändert werden. Wollen wir uns Backend danach ändern, müssen wir das **Notebook neu starten**. Dies tun wir über *Kernel -> Restart* oben in der Taskleiste.\n",
    "\n",
    "\n",
    "## 1. Vorbereitung\n",
    "\n",
    "In diesem Tutorial lernen wir die lineare Regression (ein Connectionist Neuron mit linearer Transferfunktion) näher kennen. Dazu beschäftigen wir uns mit einem konstruierten Datensatz, den wir im Folgenden laden. Außerdem müssen wir die begleitende Datei `utils_lineare_regression.py` importieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "# oder\n",
    "# %matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n",
    "\n",
    "import utils_lineare_regression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ändern Sie den Datensatz entsprechend Ihrer Gruppennummer\n",
    "# TODO: Datensatz laden\n",
    "data = pd.read_csv(\"../data/toy_automobile/toy_auto_data_A.csv\")\n",
    "\n",
    "X = data[\"Alter\"].values\n",
    "y = data[\"Verkaufspreis [Tsd €]\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e15d64677f8413897ea38e4b2ec63fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Visualisieren\n",
    "xx = np.linspace(0, 40, 100)\n",
    "\n",
    "# nicht unbedingt nötig - für Stabilität\n",
    "plt.close(\"all\")\n",
    "\n",
    "plt.figure()                       \n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Univariate Lineare Regression fitten\n",
    "\n",
    "In diesem Teil nutzen wir die Funktionen der Hilfsdatei, um eine lineare Regression interaktiv kennenzulernen. Unsere Aufgabe: wir versuchen das beste Modell zu finden, indem wir es visuell an die Daten anpassen. Dies können wir nur deshalb tun, weil wir den Spezialfall eines einzigen Features betrachten. Wir nennen die Regression deshalb *univariat*.\n",
    "\n",
    "### \"Lineare\" Regression\n",
    "\n",
    "Die \"lineare\" Regression meint hier ein Connectionist Neuron mit den normalen Features - ohne Expansion der Features. Die Vorhersagefunktion eines solchen Neurons ist in unserem Fall:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w_1 \\cdot x_1 + \\theta\n",
    "$$\n",
    "\n",
    "![lineare_regression](https://raw.githubusercontent.com/layerwise/training/main/assets/lineare_regression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88692f54bd4545d4963fb84634491cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a504869b6f49eebd17f8dcfceaf322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e399762dc5b48bba4ca288223ca36bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=1.0, continuous_update=False, description='w1', max=15.0, min=-15.0), FloatSl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nicht unbedingt nötig - für Stabilität\n",
    "plt.close(\"all\")\n",
    "\n",
    "# interaktiven Plot aufrufen\n",
    "interactive_plot, ui = utils_lineare_regression.interactive_linear_model(X, y)\n",
    "display(interactive_plot, ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratische Regression\n",
    "\n",
    "Die \"quadratische\" Regression meint hier ein Connectionist Neuron mit den ursprünglichen Features und jeweils deren Quadrat - also eine quadratische Expansion. Wichtig ist hierbei, dass wir auch dies ein **lineares** Modell nennen, denn die Gewichte kombinieren die Features weiterhin auf lineare Weise. Die Vorhersagefunktion eines solchen Neurons ist in diesem Fall:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w_2 \\cdot x_1^2 + w_1 \\cdot x_1 + \\theta\n",
    "$$\n",
    "\n",
    "![quadratische_regression](https://raw.githubusercontent.com/layerwise/training/main/assets/quadratische_regression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28c819a24c646ee9b2327db64977396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c8fd2a75ba4298af1db8840928f035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbcf4cd1b8a42d8bcbd5f7941e7c0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=0.0, continuous_update=False, description='w2', max=2.0, min=-2.0, step=0.01)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nicht unbedingt nötig - für Stabilität\n",
    "plt.close(\"all\")\n",
    "\n",
    "# interaktiven Plot aufrufen\n",
    "interactive_plot, ui = utils_lineare_regression.interactive_quadratic_model(X, y)\n",
    "display(interactive_plot, ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kubische Regression\n",
    "\n",
    "Die \"kubische\" Regression meint hier ein Connectionist Neuron mit den ursprünglichen Features, deren zweite und dritte Potenz - also eine kubische Expansion. Wichtig ist hierbei, dass wir auch dies ein **lineares** Modell nennen, denn die Gewichte kombinieren die Features weiterhin auf lineare Weise. Die Vorhersagefunktion eines solchen Neurons ist in diesem Fall:\n",
    "\n",
    "$$\n",
    "\\hat{y} = w_3 \\cdot x_1^3 + w_2 \\cdot x_1^2 + w_1 \\cdot x_1 + \\theta\n",
    "$$\n",
    "\n",
    "![kubische_regression](https://raw.githubusercontent.com/layerwise/training/main/assets/kubische_regression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92229c3ab8274735a9f791fe2b51e849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eea7baf8eb5b4ede82a9c1ba624ad38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f26344ce0a405cb475d4d5ff5712cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FloatSlider(value=0.0, continuous_update=False, description='w3', max=0.01, min=-0.01, readout_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nicht unbedingt nötig - für Stabilität\n",
    "plt.close(\"all\")\n",
    "\n",
    "# interaktiven Plot aufrufen\n",
    "interactive_plot, ui = utils_lineare_regression.interactive_cubic_model(X, y)\n",
    "display(interactive_plot, ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = [\n",
    "    (\"A\", (0.0, 0.16, -7.60, 98.00), 29.2),\n",
    "    (\"B\", (0.0, 0.11, -5.80, 89.00), 35.2),\n",
    "    (\"C\", (0.0, 0.11, -5.70, 84.00), 28.9),\n",
    "    (\"D\", (0.0, 0.11, -5.40, 85.00), 37.2),\n",
    "    (\"E\", (0.0, 0.13, -6.6, 93.0), 32.5),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelle evaluieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 10.022029625356275\n",
      "B 9.67230364657374\n",
      "C 9.232377869009824\n",
      "D 12.074896472876292\n",
      "E 9.159854050975284\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/toy_automobile/toy_auto_data_test.csv\")\n",
    "\n",
    "X_test = data[\"Alter\"].values\n",
    "y_test = data[\"Verkaufspreis [Tsd €]\"].values\n",
    "\n",
    "\n",
    "def predict(X, w3, w2, w1, theta):\n",
    "    \n",
    "    n_rows = X.shape[0]\n",
    "    y_pred = np.zeros(n_rows)\n",
    "    \n",
    "    for i in range(n_rows):\n",
    "        x_i = X[i]\n",
    "        y_pred[i] = w3 * x_i**3 + w2 * x_i**2 + w1 * x_i + theta\n",
    "        \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# auch genannt: L1-Error\n",
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / len(y_true)\n",
    "\n",
    "\n",
    "# auch genannt: L2-Error\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.sum((y_true - y_pred)**2) / len(y_true)\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return np.sqrt(np.sum((y_true - y_pred)**2) / len(y_true))\n",
    "\n",
    "\n",
    "for competitor in competitors:\n",
    "    parameter = competitor[1]\n",
    "    group = competitor[0]\n",
    "\n",
    "    y_pred = predict(X_test, parameter[0], parameter[1], parameter[2], parameter[3])\n",
    "\n",
    "    rmse = root_mean_squared_error(y_test, y_pred)\n",
    "    print(group, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bivariate Lineare Regression fitten\n",
    "\n",
    "Eine *bivariate* lineare Regression ist eine mit zwei Features. Auch diese können wir eben noch visualisieren, wenn wir zu einem 3D-Plot übergehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2baa093b79c4a839eb8a429923794ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "def true_function_2d(x1, x2):\n",
    "    f = 2 * x1 * np.sin(x2) + 0.5 * x1**2 - np.cos(x2) - 5\n",
    "    return f\n",
    "\n",
    "def true_function_2d(x1, x2):\n",
    "    return 2*x1**2 + 0.5 * x1**2 + x1*x2 + 4*x1 + 2*x2 + 5\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "x1_sample = 10 * rng.rand(100)\n",
    "x2_sample = 10 * rng.rand(100)\n",
    "f_sample = true_function_2d(x1_sample, x2_sample)\n",
    "noise = 10 * rng.randn(100)\n",
    "y_sample = f_sample + noise\n",
    "# ax.scatter(x1_sample, x2_sample, y_sample)\n",
    "\n",
    "\n",
    "#x1 = np.linspace(0, 10, 100)\n",
    "#x2 = np.linspace(0, 10, 100)\n",
    "x1 = np.linspace(-50, 50, 100)\n",
    "x2 = np.linspace(-200, 200, 100)\n",
    "\n",
    "X1, X2 = np.meshgrid(x1, x2)\n",
    "F = true_function_2d(X1, X2)\n",
    "ax.contour3D(X1, X2, F, 50, cmap=\"viridis\")\n",
    "# ax.view_init(0, 35)\n",
    "ax.view_init(45, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cace8d8879aa4c25812b138b5ef661eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6cabb204c241bc91c4aabcffac5071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='w1', max=10.0, min=-10.0), FloatSlider(value=1.0, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interactive\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "w1 = 1.0\n",
    "w2 = 1.0\n",
    "b = 0.0\n",
    "\n",
    "Y_hat = w1 * X1 + w2 * X2 + b\n",
    "y_hat_sample = w1 * x1_sample + w2 * x2_sample + b\n",
    "\n",
    "\n",
    "contour_handle = ax.contour3D(X1, X2, Y_hat, 50, cmap=\"viridis\")\n",
    "scatter_handle = ax.scatter(x1_sample, x2_sample, y_sample)\n",
    "\n",
    "error_lines_handles = [\n",
    "    ax.plot3D(\n",
    "        [xx1, xx1],\n",
    "        [xx2, xx2],\n",
    "        [yy_hat, yy],\n",
    "        linestyle=\"dashed\",\n",
    "        color=\"r\",\n",
    "        alpha=0.3        \n",
    "    )[0] for xx1, xx2, yy, yy_hat in zip(x1_sample, x2_sample, y_sample, y_hat_sample)\n",
    "]\n",
    "\n",
    "def update(w1=1.0, w2=1.0, b=0.0):\n",
    "    Y_hat = w1 * X1 + w2 * X2 + b\n",
    "    y_hat_sample = w1 * x1_sample + w2 * x2_sample + b\n",
    "    \n",
    "    global contour_handle\n",
    "    for collection in contour_handle.collections:\n",
    "        collection.remove()\n",
    "    contour_handle = ax.contour3D(X1, X2, Y_hat, 50, cmap=\"viridis\")\n",
    "    for i, error_line_handle in enumerate(error_lines_handles):\n",
    "        error_line_handle.set_data_3d(\n",
    "            [x1_sample[i], x1_sample[i]],\n",
    "            [x2_sample[i], x2_sample[i]],\n",
    "            [y_sample[i], y_hat_sample[i]]\n",
    "        )\n",
    "        \n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "interactive_plot = interactive(update, w1=(-10.0, 10.0), w2=(-10.0, 10.0), b=(-15.0, 15.0))\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
